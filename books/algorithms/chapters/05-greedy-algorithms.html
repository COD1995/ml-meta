<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Chapter 5 ‚Äî Greedy Algorithms</title>

    <link rel="stylesheet" href="../../../assets/css/base.css" />
    <link rel="stylesheet" href="../../../assets/css/inline-styles.css" />
    <link rel="stylesheet" href="../../../assets/css/chapters.css" />

    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css"
    />
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/styles/default.min.css"
    />

    <script src="../../../assets/js/mathjax-config.js"></script>

    <script
      defer
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    ></script>
    <script
      defer
      src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js"
    ></script>
    <script
      defer
      src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/highlight.min.js"
    ></script>
    <script
      defer
      src="https://cdn.jsdelivr.net/npm/highlightjs-line-numbers.js@2.8.0/dist/highlightjs-line-numbers.min.js"
    ></script>
  </head>

  <body>
    <div id="reading-progress">
      <div id="reading-progress-bar"></div>
    </div>

    <nav class="side-nav">
      <div class="side-nav-controls">
        <button
          id="homeBtn"
          class="btn-toggle"
          aria-label="Home"
          onclick="location.href='../../../index.html'"
        >
          üè†
        </button>
        <span class="nav-divider"></span>
        <button
          id="themeToggle"
          class="btn-toggle"
          aria-label="Toggle dark mode"
        >
          üåì
        </button>
      </div>

      <hr class="side-nav-divider" />

      <div id="bookNav"></div>

      <hr class="side-nav-divider" />

      <div class="coffee-banner">
        <a
          href="https://buymeacoffee.com/guoj1995"
          id="coffeeButton"
          target="_blank"
          rel="noopener noreferrer"
          aria-label="Support ML-Meta on Buy Me a Coffee"
        >
          <svg
            width="24"
            height="24"
            viewBox="0 0 24 24"
            fill="none"
            xmlns="http://www.w3.org/2000/svg"
          >
            <path d="M20 3H4V5H20V3Z" fill="currentColor" />
            <path
              d="M20 7H4C2.9 7 2 7.9 2 9V17C2 18.1 2.9 19 4 19H10C11.1 19 12 18.1 12 17V16H16C18.2 16 20 14.2 20 12V9C20 7.9 19.1 7 18 7H20Z"
              fill="currentColor"
            />
          </svg>
          <span>Support Us</span>
        </a>
      </div>

      <div class="slack-banner">
        <a
          href="https://join.slack.com/t/mlmetacommunity/shared_invite/zt-38mj0hx5v-8GyxvZ7lanC9HbywfUOwJw"
          id="slackButton"
          target="_blank"
          rel="noopener"
          aria-label="Join our Slack Community"
        >
          <svg
            xmlns="http://www.w3.org/2000/svg"
            viewBox="0 0 122.8 122.8"
            fill="#fff"
            style="width: 1.5em; height: 1.5em; vertical-align: middle"
          >
            <path d="M30.3 78.6c0 5-4 9-9 9s-9-4-9-9 4-9 9-9h9v9z" />
            <path
              d="M34.8 78.6c0-5 4-9 9-9s9 4 9 9v22.5c0 5-4 9-9 9s-9-4-9-9V78.6z"
            />
            <path d="M44 30.3c-5 0-9-4-9-9s4-9 9-9 9 4 9 9v9H44z" />
            <path
              d="M44 34.8c5 0 9 4 9 9s-4 9-9 9H21.5c-5 0-9-4-9-9s4-9 9-9H44z"
            />
            <path d="M92.5 44c0-5 4-9 9-9s9 4 9 9-4 9-9 9h-9V44z" />
            <path
              d="M88 44c0 5-4 9-9 9s-9-4-9-9V21.5c0-5 4-9 9-9s9 4 9 9V44z"
            />
            <path d="M78.8 92.5c5 0 9 4 9 9s-4 9-9 9-9-4-9-9v-9h9z" />
            <path
              d="M78.8 88c-5 0-9-4-9-9s4-9 9-9h22.5c5 0 9 4 9 9s-4 9-9 9H78.8z"
            />
          </svg>
          <span style="margin-left: 0.5em; vertical-align: middle"
            >Join our Slack</span
          >
        </a>
      </div>
    </nav>
    <div class="container content">
      <h1>Chapter 5: Greedy Algorithms</h1>
      <p>
        A game like chess can be won only by thinking ahead: a player who is
        focused entirely on immediate advantage is easy to defeat. But in many
        other games, such as Scrabble, it is possible to do quite well by simply
        making whichever move seems best at the moment and not worrying too much
        about future consequences.
      </p>
      <p>
        This sort of myopic behavior is easy and convenient, making it an
        attractive algorithmic strategy. <strong>Greedy algorithms</strong> build up a solution
        piece by piece, always choosing the next piece that offers the most
        obvious and immediate benefit. Although such an approach can be
        disastrous for some computational tasks, there are many for which it is
        optimal. Our first example is that of minimum spanning trees.
      </p>

      <section id="minimum-spanning-trees">
        <h2>5.1 Minimum spanning trees</h2>
        <p>
          Suppose you are asked to network a collection of computers by linking
          selected pairs of them. This translates into a graph problem in which
          nodes are computers, undirected edges are potential links, and the
          goal is to pick enough of these edges that the nodes are connected.
          But this is not all; each link also has a maintenance cost, reflected
          in that edge's weight. What is the cheapest possible network?
        </p>
        <figure>
          <img
            src="../../../assets/images/algorithms/chpt_5_imgs/figure-5-0a.png"
            alt="A weighted graph representing computers and potential links."
            width="500"
          />
          <figcaption>
            A graph of potential links and their costs.
          </figcaption>
        </figure>
        <p>
          One immediate observation is that the optimal set of edges cannot
          contain a cycle, because removing an edge from this cycle would reduce
          the cost without compromising connectivity:
        </p>
        <blockquote>
          <strong>Property 1:</strong> Removing a cycle edge cannot disconnect a
          graph.
        </blockquote>
        <p>
          So the solution must be connected and acyclic: undirected graphs of
          this kind are called <strong>trees</strong>. The particular tree we want is the one
          with minimum total weight, known as the minimum spanning tree (MST).
        </p>
        <blockquote>
          <strong>Input:</strong> An undirected graph $G = (V,E)$; edge weights $w_e$.<br />
          <strong>Output:</strong> A tree $T = (V,E')$, with $E' \subseteq E$, that
          minimizes weight$(T) = \sum_{e \in E'} w_e$.
        </blockquote>
        <p>In the preceding example, the minimum spanning tree has a cost of 16:</p>
        <figure>
          <img
            src="../../../assets/images/algorithms/chpt_5_imgs/figure-5-0b.png"
            alt="A minimum spanning tree for the graph."
            width="500"
          />
          <figcaption>A minimum spanning tree with a cost of 16.</figcaption>
        </figure>

        <h3>5.1.1 A greedy approach</h3>
        <p>
          Kruskal's minimum spanning tree algorithm starts with the empty graph
          and then selects edges from E according to the following rule:
        </p>
        <blockquote>
          Repeatedly add the next lightest edge that doesn't produce a cycle.
        </blockquote>
        <p>
          In other words, it constructs the tree edge by edge and, apart from
          taking care to avoid cycles, simply picks whichever edge is cheapest
          at the moment. This is a greedy algorithm: every decision it makes is
          the one with the most obvious immediate advantage.
        </p>
        <figure>
          <img
            src="../../../assets/images/algorithms/chpt_5_imgs/figure-5-1.png"
            alt="An example of Kruskal's algorithm."
            width="700"
          />
          <figcaption>
            Figure 5.1 The minimum spanning tree found by Kruskal's algorithm.
          </figcaption>
        </figure>

        <h3>5.1.2 The cut property</h3>
        <p>
          Say that in the process of building an MST, we have already
          chosen some edges $X$ and are so far on the right track. Which edge
          should we add next? The following lemma gives us flexibility.
        </p>
        <blockquote>
          <strong>Cut property:</strong> Suppose edges $X$ are part of an MST of
          $G=(V,E)$. Pick any subset of nodes $S$ for which $X$ does not cross
          between $S$ and $V-S$, and let $e$ be the lightest edge across this
          partition. Then $X \cup \{e\}$ is part of some MST.
        </blockquote>
        <p>
          A <strong>cut</strong> is any partition of the vertices into two groups, $S$ and
          $V-S$. What this property says is that it is always safe to add the
          lightest edge across any cut, provided the existing edges $X$ don't
          already cross it.
        </p>
        <figure>
          <img
            src="../../../assets/images/algorithms/chpt_5_imgs/figure-5-2.png"
            alt="Diagram illustrating the cut property."
            width="500"
          />
          <figcaption>
            Figure 5.2 The addition of edge $e$ (dotted) to tree $T$ (solid)
            produces a cycle. This cycle must contain another edge, $e'$, across
            the cut.
          </figcaption>
        </figure>
        <figure>
          <img
            src="../../../assets/images/algorithms/chpt_5_imgs/figure-5-3.png"
            alt="An example of the cut property at work."
            width="700"
          />
          <figcaption>Figure 5.3 The cut property at work.</figcaption>
        </figure>

        <h3>5.1.3 Kruskal's algorithm</h3>
        <p>
          We are ready to justify Kruskal's algorithm. At any moment, the edges
          it has chosen form a collection of connected components (a forest).
          The next edge $e$ to be added connects two of these components. Since
          $e$ is the lightest edge that doesn't produce a cycle, it is certain
          to be the lightest edge between these two components, and therefore
          satisfies the cut property.
        </p>
        <p>
          To implement this, we need a data structure that can maintain a
          collection of disjoint sets and support two operations: testing if two
          vertices belong to the same component (`find`), and merging two
          components when an edge is added (`union`).
        </p>
        <pre class="pseudocode">
            \begin{algorithm}
            \caption{Kruskal's minimum spanning tree algorithm}
            \begin{algorithmic}
              \Procedure{Kruskal}{$G, w$}
                \ForAll{$u \in V$}
                  \State $\text{makeset}(u)$
                \EndFor
                \State $X \gets \emptyset$
                \State Sort the edges $E$ by weight in non-decreasing order
                \ForAll{edge $\{u,v\} \in E$, in order of weight}
                  \If{$\text{find}(u) \neq \text{find}(v)$}
                    \State $X \gets X \cup \{\{u,v\}\}$
                    \State $\text{union}(u, v)$
                  \EndIf
                \EndFor
                \State \Return{$X$}
              \EndProcedure
            \end{algorithmic}
            \end{algorithm}
        </pre>

        <h3>5.1.4 A data structure for disjoint sets</h3>
        <p>
          The disjoint set data structure (also called Union-Find) can be
          implemented using trees. Each set is represented by a tree, with parent
          pointers going up to the root. The root acts as the representative of
          the set.
        </p>
        <figure>
          <img
            src="../../../assets/images/algorithms/chpt_5_imgs/figure-5-5.png"
            alt="A directed-tree representation of two disjoint sets."
            width="600"
          />
          <figcaption>
            Figure 5.5 A directed-tree representation of two sets.
          </figcaption>
        </figure>
        <p>
          To keep the trees shallow, we use two heuristics:
          <strong>union by rank</strong> (always attach the shorter tree to the root of
          the taller tree) and <strong>path compression</strong> (during a `find`
          operation, make every node on the path point directly to the root).
        </p>
        <figure>
            <img
              src="../../../assets/images/algorithms/chpt_5_imgs/figure-5-7.png"
              alt="The effect of path compression on the data structure."
              width="700"
            />
            <figcaption>
              Figure 5.7 The effect of path compression after find(I) and find(K).
            </figcaption>
          </figure>
        <p>
          With these optimizations, a sequence of $m$ operations on $n$ elements
          takes $O(m \alpha(n))$ time, where $\alpha(n)$ is the extremely
          slow-growing inverse Ackermann function. The cost is practically,
          though not theoretically, constant per operation.
        </p>

        <h3>5.1.5 Prim's algorithm</h3>
        <p>
          Prim's is another popular greedy algorithm for MSTs. It works by
          growing a single tree. It starts with an arbitrary node and, at each
          step, adds the cheapest possible edge that connects a vertex in the
          tree to a vertex outside the tree.
        </p>
        <figure>
          <img
            src="../../../assets/images/algorithms/chpt_5_imgs/figure-5-8.png"
            alt="Prim's algorithm growing a tree by one edge."
            width="500"
          />
          <figcaption>
            Figure 5.8 Prim's algorithm: the edges $X$ form a tree, and $S$
            consists of its vertices.
          </figcaption>
        </figure>
        <p>
          This is strongly reminiscent of Dijkstra's algorithm. The
          implementation is nearly identical, using a priority queue to store
          vertices outside the tree, keyed by the weight of the lightest edge
          connecting them to the tree.
        </p>
        <pre class="pseudocode">
            \begin{algorithm}
            \caption{Prim's minimum spanning tree algorithm}
            \begin{algorithmic}
                \Procedure{Prim}{$G, w$}
                    \ForAll{$u \in V$}
                        \State $cost(u) \gets \infty$
                        \State $prev(u) \gets \text{nil}$
                    \EndFor
                    \State Pick any initial node $u_0$
                    \State $cost(u_0) \gets 0$
                    \State $H \gets \text{makequeue}(V)$ \Comment{Priority queue, using cost-values as keys}
                    \While{$H$ is not empty}
                        \State $v \gets \text{deletemin}(H)$
                        \ForAll{each $\{v, z\} \in E$}
                            \If{$z \in H$ and $cost(z) > w(v, z)$}
                                \State $cost(z) \gets w(v, z)$
                                \State $prev(z) \gets v$
                                \State $\text{decreasekey}(H, z)$
                            \EndIf
                        \EndFor
                    \EndWhile
                \EndProcedure
            \end{algorithmic}
            \end{algorithm}
        </pre>
        <figure>
            <img
              src="../../../assets/images/algorithms/chpt_5_imgs/figure-5-9.png"
              alt="An illustration of Prim's algorithm."
              width="700"
            />
            <figcaption>
              Figure 5.9 An illustration of Prim's algorithm, starting at node A.
            </figcaption>
          </figure>
      </section>

      <section id="huffman-encoding">
        <h2>5.2 Huffman encoding</h2>
        <p>
          Huffman encoding is a greedy algorithm used for data compression.
          Given a set of symbols and their frequencies, it produces an optimal,
          prefix-free binary code (no codeword is a prefix of another).
          Frequently occurring symbols get shorter codewords, while infrequent
          symbols get longer ones.
        </p>
        <p>
          The algorithm builds a binary tree from the bottom up. It repeatedly
          finds the two symbols with the smallest frequencies, merges them into
          a new node (whose frequency is the sum of its children), and replaces
          the two original nodes with the new merged node in a priority queue.
          This continues until only one node (the root) remains.
        </p>
        <figure>
            <img
              src="../../../assets/images/algorithms/chpt_5_imgs/figure-5-10.png"
              alt="A prefix-free encoding tree."
              width="600"
            />
            <figcaption>
              Figure 5.10 A prefix-free encoding tree. Frequencies are in brackets.
            </figcaption>
          </figure>
        <pre class="pseudocode">
            \begin{algorithm}
            \caption{Huffman's encoding algorithm}
            \begin{algorithmic}
              \Procedure{Huffman}{$f$}
                \State Let $H$ be a priority queue of symbols, ordered by frequency $f$
                \ForAll{symbol $i$}
                    \State insert($H, i$)
                \EndFor
                \For{$k \gets n+1$ to $2n-1$}
                    \State $i \gets \text{deletemin}(H)$, $j \gets \text{deletemin}(H)$
                    \State Create a new node $k$ with children $i, j$
                    \State $f[k] \gets f[i] + f[j]$
                    \State insert($H, k$)
                \EndFor
              \EndProcedure
            \end{algorithmic}
            \end{algorithm}
        </pre>
      </section>

      <section id="horn-formulas">
        <h2>5.3 Horn formulas</h2>
        <p>
          In logic, a Horn formula is a set of clauses used to represent knowledge.
          A greedy algorithm can determine if a satisfying assignment exists (an
          assignment of true/false values that makes all clauses true).
        </p>
        <p>The two types of clauses are:</p>
        <ul>
            <li>
                <strong>Implications:</strong> $(x_1 \land x_2 \land \dots \land x_k) \rightarrow y$
            </li>
            <li>
                <strong>Pure negative clauses:</strong> $(\neg z_1 \lor \neg z_2 \lor \dots \lor \neg z_l)$
            </li>
        </ul>
        <p>
          The greedy strategy is to start with all variables set to `false`. It
          then repeatedly iterates through the implications. If an implication's
          left-hand side is all `true` but its right-hand side is `false`, the
          algorithm "reluctantly" sets the right-hand variable to `true`. This
          process continues until no more variables can be forced to `true`.
          Finally, it checks if this assignment satisfies all the pure negative
          clauses. If it does, a solution is found; otherwise, none exists.
        </p>
      </section>

      <section id="set-cover">
        <h2>5.4 Set cover</h2>
        <p>
          The set cover problem asks for the minimum number of sub-collections
          from a family of sets whose union covers a given universe of
          elements. For example, finding the minimum number of school locations
          to serve a county of towns.
        </p>
        <figure>
            <img
              src="../../../assets/images/algorithms/chpt_5_imgs/figure-5-11.png"
              alt="A set cover problem represented by towns and school coverage."
              width="700"
            />
            <figcaption>
              Figure 5.11 (a) Eleven towns. (b) The coverage of each potential
              school location (towns within 30 miles).
            </figcaption>
          </figure>
        <blockquote>
          <strong>SET COVER</strong><br/>
          <strong>Input:</strong> A set of elements $B$; sets $S_1, \dots, S_m \subseteq B$.<br/>
          <strong>Output:</strong> A selection of the $S_i$ whose union is $B$.<br/>
          <strong>Cost:</strong> Number of sets picked.
        </blockquote>
        <p>
          A natural greedy strategy is to repeatedly pick the set that covers the
          largest number of currently uncovered elements.
        </p>
        <p>
          This greedy algorithm is not optimal, but it provides a good
          approximation. If the optimal cover uses $k$ sets to cover $n$
          elements, the greedy algorithm will use at most $k \ln n$ sets. This
          makes it a logarithmic approximation algorithm.
        </p>
      </section>

      <section id="comments">
        <script
          src="https://utteranc.es/client.js"
          repo="COD1995/ml-meta"
          issue-term="pathname"
          label="comment"
          theme="github-light"
          crossorigin="anonymous"
          async
        ></script>
      </section>

      <footer>
        <p>
          ¬© 2025 Kristopher Kodweis ‚Ä¢
          <a
            href="https://github.com/COD1995/ml-meta"
            target="_blank"
            rel="noopener"
          >
            View on GitHub
          </a>
        </p>
      </footer>
    </div>

    <script type="module" src="../../../assets/js/main.js"></script>
    <script type="module" src="../../../assets/js/chapter-page.js"></script>

    <script src="book-data.js"></script>

    <script type="module" src="../../../assets/js/build-side-nav.js"></script>
  </body>
</html>
